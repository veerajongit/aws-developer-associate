# Amazon S3
- One of the most important building blocks of AWS
- Infinitely Scaling Storage

## S3 Buckets
- Allows people to store objects(files) in "buckets"(directories)
- Buckets must have globally unique name
- Buckets are defined at the regional level
- Naming convention 
    - No uppercase
    - No underscore
    - 3-63 characters long
    - Not na IP
    - Must start with lowercase letter or number

## S3 Object
- Objects (files) have a key
- The key is the FULL path :
    - s3://my-bucket/my_file.txt
- The key is composed of prefix + object name
- There is no concept of directories with bucket
- Keys with very long names with slashes are segregated into directories
- Object values are content of the body
    - Max Object Size is 5 TB
    - If uploading more than 5 GB, must use multi-part upload
- Metadata (list of key value pair - up to 10 - system or user data)
- Tags (Unicode key/value pair - up to 10) - useful for security/lifecycle
- Version ID (if versioning is enabled)

## S3 Versioning
- You can version your files in S3
- It must be enabled at bucket level
- Same key overwrite will increament the version eg 1, 2, 3, etc...
- Best practice to version your buckets
    - Protect against unintended deletes
    - Easy rollback to previous version
- Notes:
    - Any files that is not versioned prior to enabling versioning will have version "null"
    - Suspending versioning does not delete the previous versions

## S3 encryption for Objects
- There are 4 methods of encrypting objects in S3
    - SSE-S3: encrypts S3 objects using keys handled & managed by AWS
    - SSE-KMS: leverages AWS Key Management Service to manage encryption keys
    - SSE-C: When you want to manage your own encryption keys
    - Client side encryption

## SSE-S3
- Objects are encrypted server side
- AES-256 encryption type
- Must set header: "x-amz-server-side-encryption":"AES256"

## SSE-KMS
- Objects are encrypted server side
- KMS advantages: user control + audit rail
- Must set header: "x-amz-server-side-encryption":"aws:kms"

## SSE-C
- S3 does not store the encryption key you provide
- HTTPS must be used
- Encyption key must be provided in HTTP headers, for every HTTP request made

## Client Side Encryption
- Client library such as the Amazon S3 Encryption Client
- Clients must encrypt data themselves before sending to S3
- Clients must decrypt data themselves when retrieving from S3
- Customer fully manages the keys and encryption cycle

## Encryption in transit (SSL/TLS)
- Amazon S3 exposes
    - HTTP endpoint: non encrypted
    - HTTPS endpoint: encryption in flight
- You are free to use the endpoint you want, but HTTPS is recommended
- Most clients would use the HTTPS endpoint by default
- HTTPS is mandatory for SSE-C
- Encryption in flight is also called SSL/TLS

## S3 Security
- User based
    - IAM policies - which API calls should be allowed for a specific user from IAM console
- Resource based
    - Bucket Policies - bucket wide rules from the S3 console - allows cross account
    - Object Access Control List (ACL)- finer grain
    - Bucket Access Control List (ACL) - less common
- Not: an IAM principal can access an S3 object if
    - the user IAM permissions allow it OR the resource policy ALLOWS it
    - AND there is no explicit DENY
- Networking
    - Supports VPC Endpoints (for instance in VPC without www internet)
- Loggin and Audit
    - S2 Access Logs can be stored in other S3 bucket
    - API calls can be logged in AWS CloudTrail
- User Security
    - MFA Delete: MFA can be required in versioned buckets to delete objects
    - Pre-Signed URLs: URLs that are valid only for a limited time

## S3 Bucket Policies
- JSON based policies
    - Resources: buckets and objects
    - Actions: Set of API to Allow or Deny
    - Effect: Allow/Deny
    - Principal: The account or user to apply the policy to
- Use S3 bucket for policy to
    - Grant public access to the bucket
    - Force objects to be encrypted at upload
    - Grant access to another account (Cross account)

## Bucket settings for Blcok Public Access
- Block public access to buckets and objects granted through
    - new access control lists (ACLs)
    - any access control lists (ACLs)
    - new public bucket or access point policies
- Block public and cross account access to buckets and objects through any public bucket or access point policies
- These settings were created to prevent company data leaks
- If you know your bucket should never be public, leave it on
- Can be set at the account level

## S3 websites
- Can host static website and have tehm accessible on the www
- The website URL will be:
    - <bucket-name>.s3-website-<AWS-region>.amazonaws.com OR
    - <bucket-name>.s3-website.<AWS-region>.amazonaws.com
- If you get a 403 (Forbidden) error, make sure the bucket polic allows public reads

## CORS
- Cross Origin Resource Sharing
- An origing is a scheme(protocol), host(domain) and port
    - Eg: https://www.example.com (implied port is 443 for HTTPS, 80 for HTTP)
- Web Browser based mechanism to allow requests to other origins while visiting the main origin
- Same origin: http://example.com/app1 & http://example.com/app2
- Different origin: http://www.example.com & http://other.example.com
- The requests won't be fulfilled unless the other origin allows for the requests, using CORS headers (ex: Access-Control-Allow-Origin)
- If client does a cross-origin request on our S3 bucket, we need to enable the correct CORS headers
- You can allow for a specific origin or for * (all origins)

## S3 - Consistency Model
- Read after write consistency for PUTS of new objects
    - As soon as a new object is written, we can retrieve it (eg PUT 200=> GET 200)
    - This is true, except if we did a GET before to see if the object existed (eg GET 404 => PUT 200 => GET 404) - eventual consistent
- Eventual consistency for DELETES and PUTS of existing objects
    - If we read object after updating, we might get the older version
    eg(PUT 200 => PUT 200 =>GET 200(might be older version))
    - If we delete an object, we might still be able to retrieve it for a short time
    eg (DELETE 200 => GET 200)
- There is no way to request "strong consistency"